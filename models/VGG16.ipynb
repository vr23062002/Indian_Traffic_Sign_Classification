{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44821c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES = 59\n",
    "DATA_DIR = \"data_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "    val_test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_set = train_gen.flow_from_directory(\n",
    "        os.path.join(DATA_DIR, \"train\"),\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    val_set = val_test_gen.flow_from_directory(\n",
    "        os.path.join(DATA_DIR, \"val\"),\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    test_set = val_test_gen.flow_from_directory(\n",
    "        os.path.join(DATA_DIR, \"test\"),\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg(num_classes, fine_tune=False):\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False,\n",
    "                       input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    if fine_tune:\n",
    "        # Freeze only first 15 layers, train rest\n",
    "        for layer in base_model.layers[:15]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers[15:]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        # Freeze all layers\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    lr = 1e-5 if fine_tune else 1e-4\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ad88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title=\"Training and Validation Loss\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    train_set, val_set, test_set = prepare_data()\n",
    "\n",
    "    # Stage 1: Train with frozen VGG16\n",
    "    print(\"\\n--- Training with frozen VGG16 ---\")\n",
    "    model = build_vgg(NUM_CLASSES, fine_tune=False)\n",
    "    history = model.fit(train_set, validation_data=val_set,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)])\n",
    "    print(\"Final test accuracy (frozen):\", model.evaluate(test_set)[1])\n",
    "    print(classification_report(test_set.classes,\n",
    "                                np.argmax(model.predict(test_set), axis=1),\n",
    "                                target_names=list(test_set.class_indices.keys())))\n",
    "    model.save(\"vgg16_frozen.keras\")\n",
    "    plot_history(history, title=\"VGG16 (Frozen) Loss\")\n",
    "\n",
    "    # Stage 2: Fine-tune last conv blocks\n",
    "    print(\"\\n--- Fine-tuning VGG16 ---\")\n",
    "    ft_model = build_vgg(NUM_CLASSES, fine_tune=True)\n",
    "    history_ft = ft_model.fit(train_set, validation_data=val_set,\n",
    "                              epochs=EPOCHS,\n",
    "                              callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)])\n",
    "    print(\"Final test accuracy (fine-tuned):\", ft_model.evaluate(test_set)[1])\n",
    "    print(classification_report(test_set.classes,\n",
    "                                np.argmax(ft_model.predict(test_set), axis=1),\n",
    "                                target_names=list(test_set.class_indices.keys())))\n",
    "    #ft_model.save(\"vgg16_finetuned.keras\")\n",
    "    plot_history(history_ft, title=\"VGG16 (Fine-tuned) Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e75884",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
